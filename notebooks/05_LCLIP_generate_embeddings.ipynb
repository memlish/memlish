{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee964e6-2b6a-443f-ae34-e7bb57f82a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/jina-ai/jina-commons@v0.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730fb2c2-3be1-41f4-a957-9f6c3b4929ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install jina==3.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba9f5db-344e-4343-a92d-010b2e969762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mFutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\u001b[0m \u001b[1;30m(raised from /opt/conda/lib/python3.7/site-packages/huggingface_hub/snapshot_download.py:11)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/app/')  # noqa\n",
    "\n",
    "from jina import Document, DocumentArray, Flow, Executor, requests\n",
    "from jina.types.request import Request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import argparse\n",
    "from memlish.executors.cache import OpenAICLIPImageEncoderCache\n",
    "from memlish.executors.cache import RealSBERTEncoderCache\n",
    "from memlish.executors.index import FaissIndexer\n",
    "import torch\n",
    "import hashlib\n",
    "\n",
    "def my_hash(s): \n",
    "    return str(int(hashlib.md5(str(s).encode('utf-8')).hexdigest(), 16))\n",
    "\n",
    "from pathlib import Path\n",
    "Path.ls = lambda x: list(x.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf189c8-9913-4563-9b3d-37804986da6c",
   "metadata": {},
   "source": [
    "torch.multiprocessing.set_start_method('spawn', force=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0deeb448-23d2-4f78-b549-3c779cd687fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = Path(\"/data/imgflip/v1/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3cc19b-2349-4c15-89aa-7a5cb8226e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = IMAGE_DIR.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb45a62c-1c8f-48d3-ab73-30220abde592",
   "metadata": {},
   "outputs": [],
   "source": [
    "JINA_LCLIP_EMBEDDING_TEMPLATE_IMAGE_COLLECTION = \"02_lclip_imgflip_template_image_100k_embeddings\"\n",
    "MONGO_EMBEDDING_DB_NAME = 'memlish_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de2dcd5-aee6-4f13-9680-fdf86551ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_search_results(resp: Request):\n",
    "    for doc in resp.docs:\n",
    "        print(f'Query text: {doc.text}')\n",
    "        print(f'Matches:')\n",
    "        print('-'*10)\n",
    "        show_docs(doc.matches[:3])\n",
    "        \n",
    "def input_docs(images):\n",
    "    for img_path in images:\n",
    "        doc = Document(id=str(img_path.name), uri=str(img_path), tags={'filename': str(img_path)})\n",
    "        yield doc \n",
    "\n",
    "def show_docs(docs):\n",
    "    for doc in docs:\n",
    "        doc.load_uri_to_image_blob()\n",
    "        plt.imshow(doc.blob)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd78d3a9-1592-4093-a0af-423e5334c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_params = {\n",
    "    \"batch_size\": 8,\n",
    "    \"device\":'cpu'\n",
    "}\n",
    "\n",
    "image_cache_params = {\n",
    "    \"embedder_params\": embedder_params,\n",
    "    \"collection_name\": JINA_LCLIP_EMBEDDING_TEMPLATE_IMAGE_COLLECTION,\n",
    "    \"embedding_field_name\":'emb',\n",
    "    \"megabatch_size\":4096\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197220e-48f1-4fac-90ac-1eac2d0db46d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeeef08e-1a44-4089-ab05-85b9d6e5953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/svg/ICAgICAgICAgICAgJSV7aW5pdDp7ICAidGhlbWUiOiAiYmFzZSIsICAidGhlbWVWYXJpYWJsZXMiOiB7ICAgICAgInByaW1hcnlDb2xvciI6ICIjZmZmIiwgICAgICAicHJpbWFyeUJvcmRlckNvbG9yIjogIiNmZmYiLCAgICAgICJtYWluQmtnIjogIiMzMkM4Q0QiLCAgICAgICJjbHVzdGVyQmtnIjogIiNFRUVERTc4QyIsICAgICAgInNlY29uZGFyeUJvcmRlckNvbG9yIjogIm5vbmUiLCAgICAgICJ0ZXJ0aWFyeUJvcmRlckNvbG9yIjogIm5vbmUiLCAgICAgICJsaW5lQ29sb3IiOiAiI2E2ZDhkYSIgICAgICB9fX0lJSAgICAgICAgICAgIApmbG93Y2hhcnQgTFI7CnN1YmdyYXBoIENMSVBJbWFnZUVuY29kZXJDYWNoZTsKQ0xJUEltYWdlRW5jb2RlckNhY2hlL3BlYS0wW09wZW5BSUNMSVBJbWFnZUVuY29kZXJDYWNoZV06OjpQRUE7CmVuZDsKZ2F0ZXdheXN0YXJ0W2dhdGV3YXldOjo6R0FURVdBWSAtLT4gQ0xJUEltYWdlRW5jb2RlckNhY2hlOjo6UE9EOwpDTElQSW1hZ2VFbmNvZGVyQ2FjaGU6OjpQT0QgLS0+IGdhdGV3YXllbmRbZ2F0ZXdheV06OjpHQVRFV0FZOwpjbGFzc0RlZiBJTlNQRUNUIHN0cm9rZTojRjI5QzlGCmNsYXNzRGVmIEpPSU5fSU5TUEVDVCBzdHJva2U6I0YyOUM5RgpjbGFzc0RlZiBHQVRFV0FZIGZpbGw6bm9uZSxjb2xvcjojMDAwLHN0cm9rZTpub25lCmNsYXNzRGVmIElOU1BFQ1RfQVVYX1BBU1Mgc3Ryb2tlLWRhc2hhcnJheTogMiAyCmNsYXNzRGVmIEhFQURUQUlMIGZpbGw6IzMyQzhDRDFECgpjbGFzc0RlZiBFWFRFUk5BTCBmaWxsOiNmZmYsc3Ryb2tlOiMzMkM4Q0Q=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jina import Flow\n",
    "flow_index = Flow().add(uses=OpenAICLIPImageEncoderCache, name=\"CLIPImageEncoderCache\", uses_with=image_cache_params)\n",
    "flow_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a475031-cc4e-4677-8f72-07eb7efa4eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install protobuf==3.13.0\n",
    "# # !pip install jupyter\n",
    "# !pip install ipywidgets widgetsnbextension pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c4ada4-67ea-43a3-ab00-003122ab7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unset https_proxy;unset http_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b454ec1d-fde3-4a18-944f-438ec6b9b44e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠙\u001b[0m 1/2 waiting \u001b[33mCLIPImageEncoderCache\u001b[0m to be ready...                                OpenAICLIPImageEncoder is here!!!!!!!\n",
      "           Flow@996[I]:\u001b[32m🎉 Flow is ready to use!\u001b[0m                                            \n",
      "\t🔗 Protocol: \t\t\u001b[1mGRPC\u001b[0m\n",
      "\t🏠 Local access:\t\u001b[4m\u001b[36m0.0.0.0:39859\u001b[0m\n",
      "\t🔒 Private network:\t\u001b[4m\u001b[36m172.19.0.2:39859\u001b[0m\n",
      "\t🌐 Public address:\t\u001b[4m\u001b[36m3.251.68.86:39859\u001b[0m\u001b[0m\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:00\u001b[0m estimating... "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b215468387c44c3a1c9f5c1d0e7c99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:05\u001b[0m estimating... {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:42:31.137978', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.707905530929565}\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:05\u001b[0m estimating... "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ecbd05e9244c29873422d04623249d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:11\u001b[0m  0.0 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:42:37.125449', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.90233039855957}\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:11\u001b[0m  0.0 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8b1531a92d40f1816481e8c61932c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:17\u001b[0m  0.1 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:42:42.657090', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.476998329162598}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e9b01b60fe4faebef3918bd565be01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:22\u001b[0m  0.1 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:42:48.132228', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.421765089035034}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9408c13945b42c09e108805fa7836d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:28\u001b[0m  0.1 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:42:53.541933', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.35018515586853}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce93b446060445419b6ee7086c28442e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:33\u001b[0m  0.1 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:42:59.225651', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.63321328163147}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5288f3e7d85e405cbae91c0c32e9a92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:40\u001b[0m  0.1 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:05.779889', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.494457483291626}\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:40\u001b[0m  0.1 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8845fcc976574cbb89dcc118798bd40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:45\u001b[0m  0.1 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:11.265924', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.418973684310913}\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:45\u001b[0m  0.1 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde943cf70a7486797c8ce8d59fcad34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:52\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:17.449375', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.127509593963623}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39a95aa17d4448a90e2367dfacc80ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:52\u001b[0m  0.2 step/s OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:57\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:22.942366', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.430494546890259}\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:57\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e0d378d16a4256bb91dd16d7b852de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:03\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:28.593247', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.585848331451416}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75357bdfa664f8691abb7a416d3cd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:08\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:34.056252', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.399879217147827}\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:08\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6460d507f84a7dbabba2998e2b469c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:14\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:39.948793', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.836594581604004}\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:14\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458be974c9524d7bb4ae311442bea7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:20\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:45.617657', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.599672079086304}\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:20\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4dd037d97340f4b809f7f2d6cd7393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:25\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:51.095100', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.409838438034058}\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:25\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eecf43a6f4f43058ee321fa6d1413cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:32\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:43:57.450081', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.2954723834991455}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e66dfc261540d387f013b01677f319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:38\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:03.568276', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.059837818145752}\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:38\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166d1880bcc041c28cbd975f9c1b96ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:44\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:09.613145', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.953862190246582}\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:44\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32418b583dfa427190078b3aa3079abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:49\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:15.029859', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.34907603263855}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5595da5fcb74824aa4e623510430a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:55\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:20.565997', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.476935148239136}\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:01:55\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f271ce6124467d8b7ba6e1710775cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:00\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:26.170227', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.539580583572388}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da3986c0a704d6395a78d64fb2e27fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:06\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:31.538350', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.310930490493774}\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:06\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1ffc07de16491596780c7bfe9a4977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:11\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:37.219949', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.62087082862854}\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:11\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5173a9c3f88c4efe9a106e10591f6889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:17\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:43.131794', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.847360849380493}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807e7b81422949dabc9851088a1ced15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:23\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:48.510259', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.30961537361145}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500bc4c7b1fc47569ad0f3d7caf21dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:28\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:54.101999', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.522747993469238}\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:28\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7f1103ec034d87956bcaa62227d8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:34\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:44:59.602859', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.43470025062561}\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:34\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990b09dc561a4559ac87e39d8aae9228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:41\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:45:06.801863', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 7.125728368759155}\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━\u001b[0m \u001b[36m0:02:41\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e93cfd7774447bb229afb566f082f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━\u001b[0m \u001b[36m0:02:47\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:45:12.980339', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.113158464431763}\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━\u001b[0m \u001b[36m0:02:47\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e367b7dfe9294abe90b9ca6ad4781ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━\u001b[0m \u001b[36m0:02:53\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:45:18.943511', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.892398118972778}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bc3b94d30a496e8a67c22323892665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━\u001b[0m \u001b[36m0:02:59\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:45:24.852098', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.845844268798828}\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━\u001b[0m \u001b[36m0:02:59\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25aedf29e64d4c36ab628bd167ea0c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━\u001b[0m \u001b[36m0:03:04\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:45:30.333234', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.4215192794799805}\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━\u001b[0m \u001b[36m0:03:05\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575b0a7b5a7746c0b7c33df6e7bec8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━\u001b[0m \u001b[36m0:03:10\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:45:35.860036', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.452575922012329}\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━\u001b[0m \u001b[36m0:03:10\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960dca68785344138b64b8fa7692bfc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━\u001b[0m \u001b[36m0:03:16\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:45:41.480093', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.5406999588012695}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7770174c79864ee7abfce048964f0407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━\u001b[0m \u001b[36m0:03:22\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:45:47.957771', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.40624737739563}\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━\u001b[0m \u001b[36m0:03:22\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfa7ba334164f4fbda7f17eec28114c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━\u001b[0m \u001b[36m0:03:28\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:45:53.848315', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.814522743225098}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9217708c702941cfbf4b1fe6dcefb26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━\u001b[0m \u001b[36m0:03:34\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:00.035604', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.097354412078857}\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━\u001b[0m \u001b[36m0:03:34\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22a56a1d18f4f038e195bb13d845a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━\u001b[0m \u001b[36m0:03:41\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:06.671910', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.5604095458984375}\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━\u001b[0m \u001b[36m0:03:41\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338b1f982c5b48f996f2b4ece5b6df46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━\u001b[0m \u001b[36m0:03:46\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:12.179298', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.4294140338897705}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd81ac8c7594cd5a4803a02442312e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m\u001b[0m \u001b[36m0:03:52\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:18.430670', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.1786158084869385}\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m\u001b[0m \u001b[36m0:03:53\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848d501dfa4d4cd9a0ebf74626b148cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:03:58\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:24.096584', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.593934774398804}\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:03:58\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c7a65be95e4bb5bef8ba2567d40587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:04\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:29.695244', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.501974582672119}\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:04\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e950014d46f746e5ad63b46ae772ffb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:10\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:35.481432', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.7033421993255615}\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:10\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9530339e03084cc99d924bb0cfffd4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:16\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:41.608727', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.036006212234497}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e0324b8a4440539f851407536de67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:22\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:47.745656', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.065611124038696}\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:22\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9b0e0075094ff3b2038cfdfe58b269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:28\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:53.577667', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.757988929748535}\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:28\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e64e1d4d95143b193a27f3eecd634f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:33\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:46:59.301770', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.651822328567505}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0abd1af23d42f593050a3266a959e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:42\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:47:07.948112', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 8.577431201934814}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efef0f0989c46bd83afc654b6085958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:48\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:47:13.447819', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.420974969863892}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558e5c80aef84332bc232e53dbf620c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:54\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:47:19.411755', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.884244680404663}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5dcb86b0d04b2bb42e4f157506ad69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:04:59\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:47:25.207072', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.71703577041626}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad59e2ed2af0413890ea140861f7f22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:05\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:47:30.923580', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.629546880722046}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67de0fcb95144d397d29ae183650aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:05\u001b[0m  0.2 step/s OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:11\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:47:36.796083', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.8043906688690186}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9df816338c49a19827edf80adf15f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:16\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:47:42.326751', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.449605703353882}\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:16\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9066712c67204590a3f416e305131422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:22\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:47:48.041812', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.6417036056518555}\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:22\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf278dd224843ec8c34ada4f95753ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:29\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:47:54.777130', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.656376123428345}\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:29\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f6ea03f3624ae1b13d96211f47f40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:35\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:00.915760', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.062650918960571}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754e98094f5548c49b83697729d3e492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:42\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:08.340067', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 7.344797372817993}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1eeadda533f461db2fd985761ecb915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:43\u001b[0m  0.2 step/s \n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:48\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:14.084144', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.656209945678711}\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:48\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393ef486f1d546248dee0a444b543d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:55\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:20.812491', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.648495435714722}\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:05:55\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f9bbddcb454239a7c61bc89080a23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:01\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:26.516950', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.626309394836426}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1740f32615e4c43a97a0fa334d190db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:06\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:31.956021', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.356682300567627}\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:06\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e250a771f74b02980c210e48b9e066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:12\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:37.779282', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.733776569366455}\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:12\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c64397d385b4fafb6d85e16c92294de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:17\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:43.265700', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.405743598937988}\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:17\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b45c2a7b3c4336b0efc7a86adacb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:23\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:48.704197', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.375272750854492}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e656a004cb4850a103cf9b49eee842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:28\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:54.115421', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.342024564743042}\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:28\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d94a0c0d504b3db303259917550beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:34\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:48:59.892372', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.7065064907073975}\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:34\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4d901241b3453fac4874e6590b4972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:42\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:49:07.845541', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 7.875820875167847}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d58d6ee92034fc5978774937201d77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━\u001b[0m \u001b[36m0:06:42\u001b[0m  0.2 step/s OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━\u001b[0m \u001b[36m0:06:47\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:49:13.331804', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.420569896697998}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97825c6d7e274977b639774338bc1124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━\u001b[0m \u001b[36m0:06:48\u001b[0m  0.2 step/s OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━\u001b[0m \u001b[36m0:06:54\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:49:19.743695', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.338769435882568}\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━\u001b[0m \u001b[36m0:06:54\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e062275ecdc0466e92a2be919b5db28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━\u001b[0m \u001b[36m0:07:00\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:49:26.329877', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.506046772003174}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6daf84dcd894d2788fcee75c1d03e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━\u001b[0m \u001b[36m0:07:06\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:49:32.147691', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.7386462688446045}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff17e5b3c384331b82ff0dec6952928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━\u001b[0m \u001b[36m0:07:06\u001b[0m  0.2 step/s OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━\u001b[0m \u001b[36m0:07:13\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:49:38.531926', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.3032002449035645}\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━\u001b[0m \u001b[36m0:07:13\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825f38d195e548c2a10a6c692959c9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━\u001b[0m \u001b[36m0:07:19\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:49:45.093293', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.424337148666382}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3094acfe5913469a9a92b0959cf649e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━\u001b[0m \u001b[36m0:07:19\u001b[0m  0.2 step/s OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━\u001b[0m \u001b[36m0:07:26\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:49:51.562516', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 6.393615007400513}\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━\u001b[0m \u001b[36m0:07:26\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b866ec8d463400789177dd587598789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━\u001b[0m \u001b[36m0:07:33\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:49:58.870335', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 7.233217000961304}\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━\u001b[0m \u001b[36m0:07:33\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9364d7be034ae3832d7ebbc748c8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━\u001b[0m \u001b[36m0:07:43\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:50:08.964015', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 10.005352973937988}\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━\u001b[0m \u001b[36m0:07:43\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b36b00baaec4c528fa699c387af5ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━\u001b[0m \u001b[36m0:07:52\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:50:18.001949', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 8.929155588150024}\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━\u001b[0m \u001b[36m0:07:52\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9070be6aba654d6e80e12931f577978c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━\u001b[0m \u001b[36m0:08:01\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:50:26.969365', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 8.854691982269287}\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m\u001b[0m \u001b[36m0:08:01\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730002a207c044069c9ac29c54aeedfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m\u001b[0m \u001b[36m0:08:09\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:50:35.254387', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 8.154273271560669}\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m\u001b[0m \u001b[36m0:08:09\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f7ac23fc6f4123aa9b0220e7b4c94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:17\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:50:43.019517', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 7.655085325241089}\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:17\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4185473bb6454e369a04ae0f3fc7d6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:25\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:50:51.314477', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 8.200188159942627}\n",
      "\u001b[32m⠼\u001b[0m Working... \u001b[32m━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:25\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b37f5ce20b4e50bed4b00d6093c51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:35\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:51:00.956714', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 9.534698724746704}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9500d15c844843b54c56fd453e90b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:45\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:51:10.633195', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 9.579256296157837}\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:45\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841f2833a2774b7bb8f401d33ce9ae84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:45\u001b[0m  0.2 step/s OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:54\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:51:19.801448', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 9.059681177139282}\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:08:54\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b30cf949b14eec92428e4124a43a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:03\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:51:28.906293', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 9.024463176727295}\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:03\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd7074880904ca2b7e19f42c1a1f354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:12\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:51:37.892584', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 8.911600589752197}\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:12\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6111d5e0c93b4a10b247a040471cc83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:21\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:51:47.019521', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 9.039519548416138}\n",
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:21\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9648e7de04174a64be68f7f364109120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:30\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:51:55.952598', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 8.85389494895935}\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:30\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3776aeb4f35475b809ab9bc9c46a25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:38\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:52:04.251284', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 8.182371616363525}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c265da74c345648b4b6f99f816646b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m⠇\u001b[0m Working... \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:38\u001b[0m  0.2 step/s OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠧\u001b[0m Working... \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:46\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:52:11.495150', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 7.143779039382935}\n",
      "\u001b[32m⠏\u001b[0m Working... \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:46\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf7581898974f3a92b81e5980016c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠋\u001b[0m Working... \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:55\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:52:20.929592', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 9.321268081665039}\n",
      "\u001b[32m⠙\u001b[0m Working... \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:09:55\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2a7628d3e142e79dc7fdf612f90682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:10:04\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:52:30.338634', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 9.311448097229004}\n",
      "\u001b[32m⠸\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:10:04\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc44482757e4411fb840a9233ed09395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠹\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:10:10\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:52:36.390908', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 5.945720672607422}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69223422f2cb42458ca02b48ead73f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:10:18\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:52:43.886078', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 7.42069673538208}\n",
      "\u001b[32m⠦\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:10:18\u001b[0m  0.2 step/s "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e14d569b19e4ecfae75f53a9874f514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAICLIPImageEncoder.get_embeddings is here!!!!!!!\n",
      "\u001b[32m⠴\u001b[0m Working... \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[32m╸\u001b[0m\u001b[2m\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:10:26\u001b[0m  0.2 step/s {'es_tag': 'TIMELOG', 'timestamp': '2022-11-01 15:52:52.060305', 'function': 'memlish.executors.openai_clip.get_embeddings', 'duration': 8.065152168273926}\n",
      "\u001b[32m⠇\u001b[0m       DONE \u001b[33m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[33m╸\u001b[0m\u001b[2m\u001b[33m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:10:26\u001b[0m  0.2 step/s \u001b[K97 steps done in 10 minutes and 26 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mDeprecationWarning: clear_current is deprecated\u001b[0m \u001b[1;30m(raised from /opt/conda/lib/python3.7/site-packages/jina/peapods/zmq/__init__.py:607)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with flow_index:\n",
    "    flow_index.post(on='',inputs=input_docs(images), request_size=10, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8211a5-64c3-4f19-9b01-382dbc8c901f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
